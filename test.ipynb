{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093dd3d-f8aa-4595-885c-e93bb9545cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 23:49:50.529506: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 23:49:50.723586: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-11 23:49:51.238208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fkirsch/anaconda3/envs/iannwtf/lib/\n",
      "2023-03-11 23:49:51.238287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fkirsch/anaconda3/envs/iannwtf/lib/\n",
      "2023-03-11 23:49:51.238293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-11 23:49:52.258037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:52.266098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:52.266260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:52.266862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 23:49:52.269903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:52.270004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:52.270086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:53.013234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:53.013353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:53.013365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-11 23:49:53.013430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-11 23:49:53.013465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4597 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 980 Ti, pci bus id: 0000:01:00.0, compute capability: 5.2\n",
      "2023-03-11 23:49:54.220563: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-03-11 23:49:54.568099: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-11 23:49:54.618785: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-11 23:49:54.618857: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-11 23:49:54.670392: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-11 23:49:54.670504: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "  0%|                                                                                          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.1614678899082569\n",
      "Loss  0 :  401.41953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                           | 100/5000 [52:02<56:08:44, 41.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.0984182776801406\n",
      "Loss  100 :  416.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                        | 200/5000 [2:13:15<73:49:47, 55.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.11307420494699646\n",
      "Loss  200 :  118.86865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▌                                                                      | 300/5000 [3:49:18<74:13:16, 56.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.10488245931283906\n",
      "Loss  300 :  492.83987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████                                                                     | 400/5000 [5:27:42<45:54:31, 35.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.07705192629815745\n",
      "Loss  400 :  45.289745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                   | 500/5000 [6:56:49<66:48:30, 53.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.1303538175046555\n",
      "Loss  500 :  1210.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████                                                                  | 600/5000 [8:23:27<60:51:04, 49.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.13559322033898305\n",
      "Loss  600 :  1242.0934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▌                                                                | 700/5000 [9:47:31<50:03:48, 41.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.1\n",
      "Loss  700 :  763.06165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▊                                                              | 800/5000 [11:00:55<56:25:46, 48.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Agent average reward: 0.125\n",
      "Loss  800 :  934.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▍                                                             | 841/5000 [11:33:01<46:39:27, 40.39s/it]"
     ]
    }
   ],
   "source": [
    "from keras_gym_env import ConnectFourEnv\n",
    "from env_wrapper import ConnectFourSelfPLay\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import random as rnd\n",
    "\n",
    "from agent import DQNAgent\n",
    "from buffer import Buffer\n",
    "from training import train_self_play_best\n",
    "\n",
    "\n",
    "# seeds\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "rnd.seed(seed)\n",
    "\n",
    "#Subfolder for Logs\n",
    "config_name = \"best_agent\"\n",
    "#createsummary writer for vusalization in tensorboard    \n",
    "time_string = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# time_string = \"\"\n",
    "\n",
    "best_train_path = f\"logs/{config_name}/{time_string}/best_train\"\n",
    "best_train_writer = tf.summary.create_file_writer(best_train_path)\n",
    "model_path_best = f\"model/{config_name}/{time_string}/best\"\n",
    "\n",
    "# Hyperparameter\n",
    "iterations = 5000\n",
    "INNER_ITS = 50\n",
    "BATCH_SIZE = 512\n",
    "#reward_function_adapting_agent = lambda d,r: tf.where(d, tf.where(r==0.0,tf.constant(1.0),tf.constant(0.0)), r)\n",
    "epsilon = 1\n",
    "EPSILON_MIN = 0.01\n",
    "EPSILON_DECAY = 0.995\n",
    "POLYAK = 0.9\n",
    "dropout_rate = 0.5, \n",
    "normalisation = True\n",
    "\n",
    "# create buffer\n",
    "best_buffer = Buffer(capacity = 100000,min_size = 30000)\n",
    "\n",
    "# create agent\n",
    "env = ConnectFourEnv()\n",
    "env = ConnectFourSelfPLay(ConnectFourEnv)\n",
    "best_agent = DQNAgent(env,best_buffer, batch = BATCH_SIZE, model_path = model_path_best, polyak_update = POLYAK, inner_iterations = INNER_ITS, dropout_rate = dropout_rate, normalisation = normalisation)\n",
    "\n",
    "train_self_play_best(best_agent, BATCH_SIZE, iterations, best_train_writer, epsilon= epsilon, epsilon_decay = EPSILON_DECAY,epsilon_min = EPSILON_MIN,env = env)\n",
    "\n",
    "\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de6ae4f6-ea35-4e86-bcf1-a928da5c537d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b41201f8d90ef9b0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b41201f8d90ef9b0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"logs/test_agent/20230311-170048\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d40023a-c607-4dce-883b-74a241c94352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus object at 0x7f43081b7ac0>\n"
     ]
    }
   ],
   "source": [
    "#Values to create a model to load_weights\n",
    "\n",
    "\n",
    "from keras_gym_env import ConnectFourEnv\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "from agent import DQNAgent\n",
    "from buffer import Buffer\n",
    "from training import train_self_play_best\n",
    "\n",
    "#Subfolder for Logs\n",
    "config_name = \"best_agent_2\"\n",
    "#createsummary writer for vusalization in tensorboard    \n",
    "time_string = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# time_string = \"\"\n",
    "\n",
    "best_train_path = f\"logs/{config_name}/{time_string}/best_train\"\n",
    "#adapting_train_path = f\"logs/{config_name}/{time_string}/adapting_train\"\n",
    "best_train_writer = tf.summary.create_file_writer(best_train_path)\n",
    "#dapting_train_writer = tf.summary.create_file_writer(adapting_train_path)\n",
    "\n",
    "#best_test_path = f\"logs/{config_name}/{time_string}/best_test\"\n",
    "#adapting_test_path = f\"logs/{config_name}/{time_string}/adapting_test\"\n",
    "#best_test_writer = tf.summary.create_file_writer(best_test_path)\n",
    "#adapting_test_writer = tf.summary.create_file_writer(adapting_test_path)\n",
    "\n",
    "#train_writer = [best_train_writer, adapting_train_writer]\n",
    "#test_writer = [best_test_writer, adapting_test_writer]\n",
    "\n",
    "model_path_best = f\"model/{config_name}/{time_string}/best\"\n",
    "#model_path_adapting = f\"model/{config_name}/{time_string}/adapting\"\n",
    "\n",
    "# Hyperparameter\n",
    "iterations = 1000\n",
    "INNER_ITS = 500\n",
    "BATCH_SIZE = 6\n",
    "reward_function_adapting_agent = lambda d,r: tf.where(d, tf.where(r==0.0,tf.constant(1.0),tf.constant(0.0)), r)\n",
    "epsilon = 1 #TODO\n",
    "EPSILON_DECAY = 0.99\n",
    "POLYAK = 0.9\n",
    "\n",
    "# create buffer\n",
    "best_buffer = Buffer(100000,1000)\n",
    "#adapting_buffer = Buffer(100000,1000)\n",
    "\n",
    "\n",
    "env = ConnectFourEnv()\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "best_agent = DQNAgent(env,best_buffer, batch = BATCH_SIZE, model_path = model_path_best, polyak_update = POLYAK, inner_iterations = INNER_ITS)\n",
    "best_agent = best_agent.model.load_weights(f'model/best_agent/20230309-155156/best/200') # small loss after 200 iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93fa077e-84ca-4ca4-8374-2f535448ee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus object at 0x7f43081b7ac0>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91377645-3090-4f87-a06e-99519b8db1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  0\n",
      "  ●   ●   ●   ●   ●   ●   ●  \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      " 0\n",
      "Turn Player  1\n",
      "      ●   ●   ●   ●   ●   ●  \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CheckpointLoadStatus' object has no attribute 'select_action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     input_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m())\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     input_action \u001b[38;5;241m=\u001b[39m \u001b[43mbest_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m()\n\u001b[1;32m     23\u001b[0m state, r, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(input_action)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(done):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CheckpointLoadStatus' object has no attribute 'select_action'"
     ]
    }
   ],
   "source": [
    "player = 0\n",
    "best_agent = DQNAgent(env,best_buffer, batch = BATCH_SIZE, model_path = model_path_best, polyak_update = POLYAK, inner_iterations = INNER_ITS)\n",
    "best_agent = best_agent.model.load_weights(f'model/best_agent/20230309-155156/best/200') # weights for small loss after 200 iterations\n",
    "\n",
    "\n",
    "while(True):\n",
    "\n",
    "    print(\"Turn Player \", player)\n",
    "    env.render()\n",
    "    #print(state)\n",
    "    if not player:\n",
    "        input_action = int(input())\n",
    "    else:\n",
    "        \n",
    "        input_action = best_agent.select_action()\n",
    "\n",
    "    state, r, done, info = env.step(input_action)\n",
    "    \n",
    "    if(done):\n",
    "        print(\"Player \", player, \" wins\") if r == 1 else print(\"Draw\")\n",
    "        env.render()\n",
    "        #print(state)\n",
    "        break\n",
    "\n",
    "    player = int(not player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e050e-0616-4879-bf09-45cbb7b6152f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
