{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c9a9f4b-1b81-423f-a9c0-8e1c02f705b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 10:10:53.904187: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 10:10:54.094186: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-13 10:10:54.733380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fkirsch/anaconda3/envs/iannwtf/lib/\n",
      "2023-03-13 10:10:54.733463: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fkirsch/anaconda3/envs/iannwtf/lib/\n",
      "2023-03-13 10:10:54.733470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd896e21-c21c-4dd3-a1c4-0322a0a6988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e62199d09e17acc9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e62199d09e17acc9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"logs/best_agent/20230312-115349\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3778db-ee85-4a4d-b415-27a2e91e2732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 10:12:55.113292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.122459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.122643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.123289: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 10:12:55.125587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.125764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.125902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.885180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.885358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.885375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-13 10:12:55.885493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-13 10:12:55.885554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4420 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 980 Ti, pci bus id: 0000:01:00.0, compute capability: 5.2\n",
      "2023-03-13 10:16:01.689220: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-03-13 10:16:43.584450: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-13 10:16:43.676820: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-13 10:16:43.676896: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-13 10:16:43.802064: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-13 10:16:43.805503: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "### from env_wrapper import ConnectFourSelfPLay\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import random as rnd\n",
    "\n",
    "from env_wrapper import ConnectFourSelfPLay\n",
    "from agent import DQNAgent\n",
    "from buffer import Buffer\n",
    "from training import train_self_play_best\n",
    "\n",
    "# seeds\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "rnd.seed(seed)\n",
    "\n",
    "#Subfolder for Logs\n",
    "config_name = \"best_agent\"\n",
    "#createsummary writer for vusalization in tensorboard    \n",
    "time_string = \"20230312-115349\"\n",
    "# time_string = \"\"\n",
    "\n",
    "best_train_path = f\"logs/{config_name}/{time_string}/best_train\"\n",
    "best_train_writer = tf.summary.create_file_writer(best_train_path)\n",
    "model_path_best = f\"model/{config_name}/{time_string}/best\"\n",
    "\n",
    "# Hyperparameter\n",
    "iterations = 5000\n",
    "INNER_ITS = 50\n",
    "BATCH_SIZE = 512\n",
    "#reward_function_adapting_agent = lambda d,r: tf.where(d, tf.where(r==0.0,tf.constant(1.0),tf.constant(0.0)), r)\n",
    "epsilon = 1\n",
    "EPSILON_MIN = 0.01\n",
    "EPSILON_DECAY = 0.995\n",
    "POLYAK = 0.9\n",
    "dropout_rate = 0.2, \n",
    "normalisation = True\n",
    "\n",
    "# create buffer\n",
    "best_buffer = Buffer(capacity = 100000,min_size = 5000)\n",
    "\n",
    "# create agent\n",
    "env = ConnectFourSelfPLay()\n",
    "best_agent = DQNAgent(env,best_buffer, batch = BATCH_SIZE, model_path = model_path_best, polyak_update = POLYAK, inner_iterations = INNER_ITS, dropout_rate = dropout_rate, normalisation = normalisation)\n",
    "\n",
    "best_agent.load_models(2000)\n",
    "env.set_opponent(best_agent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a97098-e764-47be-a13b-b51e7d84932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●   ●   ●   ●      \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●   ●   ●   ●      \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●   ●   ●   ●      \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ | ○ |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●   ●   ●   ●      \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ | ○ |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ | ○ |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Player  1  wins\n",
      "  ●   ●   ●   ●   ●   ●      \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ | ○ |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   | ○ | ○ |   |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "player = 0\n",
    "done=False\n",
    "while(True):\n",
    "\n",
    "    print(\"Turn Player \", player)\n",
    "    #print(state)\n",
    "    if not player:\n",
    "        input_action = int(input())\n",
    "    else:  \n",
    "        \n",
    "        state, r, done, info = env.step(input_action)\n",
    "        env.render()\n",
    "    \n",
    "    if(done):\n",
    "        print(\"Player \", player, \" wins\") if r == 1 or r ==-1 else print(\"Draw\")\n",
    "        env.render()\n",
    "        #print(state)\n",
    "        break\n",
    "\n",
    "    player = int(not player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98144a-a9a4-47c7-aa54-5e12b88a7652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
