{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c9a9f4b-1b81-423f-a9c0-8e1c02f705b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 09:29:46.765228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 09:29:46.939129: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-12 09:29:47.633302: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fkirsch/anaconda3/envs/iannwtf/lib/\n",
      "2023-03-12 09:29:47.633404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fkirsch/anaconda3/envs/iannwtf/lib/\n",
      "2023-03-12 09:29:47.633412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd896e21-c21c-4dd3-a1c4-0322a0a6988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c53b523b2ccb49ac\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c53b523b2ccb49ac\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"logs/best_agent/20230311-234952\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c79b158-23c6-4360-a703-1812e1e532ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d97c0284038476a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d97c0284038476a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"logs/test_agent/20230311-170048\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d5a99c-a7e9-4895-b136-3c9a493c74ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 11:23:51.137913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 11:23:51.365079: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-12 11:23:51.994381: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fkirsch/anaconda3/envs/iannwtf/lib/\n",
      "2023-03-12 11:23:51.994566: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fkirsch/anaconda3/envs/iannwtf/lib/\n",
      "2023-03-12 11:23:51.994577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-12 11:23:53.012779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:53.024064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:53.024119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:53.024528: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 11:23:53.051482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:53.051550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:53.051586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:54.249475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:54.249584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:54.249596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-12 11:23:54.249646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-12 11:23:54.249685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4125 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 980 Ti, pci bus id: 0000:01:00.0, compute capability: 5.2\n",
      "2023-03-12 11:24:06.997252: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-03-12 11:24:13.453625: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-12 11:24:13.503822: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-12 11:24:13.503879: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-12 11:24:13.559679: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-12 11:24:13.559817: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (128,) when attempting to restore variable with shape (64,) and name dense_list/0/bias/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m env \u001b[38;5;241m=\u001b[39m ConnectFourSelfPLay(ConnectFourEnv)\n\u001b[1;32m     46\u001b[0m best_agent \u001b[38;5;241m=\u001b[39m DQNAgent(env,best_buffer, batch \u001b[38;5;241m=\u001b[39m BATCH_SIZE, model_path \u001b[38;5;241m=\u001b[39m model_path_best, polyak_update \u001b[38;5;241m=\u001b[39m POLYAK, inner_iterations \u001b[38;5;241m=\u001b[39m INNER_ITS, dropout_rate \u001b[38;5;241m=\u001b[39m dropout_rate, normalisation \u001b[38;5;241m=\u001b[39m normalisation)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mbest_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m env\u001b[38;5;241m.\u001b[39mset_opponent(best_agent)\n",
      "File \u001b[0;32m~/Uni/tensor/Self-Play_DQN_Project/agent.py:101\u001b[0m, in \u001b[0;36mDQNAgent.load_models\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_models\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/model/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/target_model/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/iannwtf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/iannwtf/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py:135\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    132\u001b[0m   assigned_variable \u001b[38;5;241m=\u001b[39m resource_variable_ops\u001b[38;5;241m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[1;32m    133\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_op, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape, restored_tensor)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived incompatible tensor with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestored_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen attempting to restore variable with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[0;31mValueError\u001b[0m: Received incompatible tensor with shape (128,) when attempting to restore variable with shape (64,) and name dense_list/0/bias/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    "from keras_gym_env import ConnectFourEnv\n",
    "from env_wrapper import ConnectFourSelfPLay\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import random as rnd\n",
    "\n",
    "from agent import DQNAgent\n",
    "from buffer import Buffer\n",
    "from training import train_self_play_best\n",
    "\n",
    "\n",
    "# seeds\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "rnd.seed(seed)\n",
    "\n",
    "#Subfolder for Logs\n",
    "config_name = \"test_agent\"\n",
    "#createsummary writer for vusalization in tensorboard    \n",
    "time_string = \"20230311-170048\"\n",
    "# time_string = \"\"\n",
    "\n",
    "best_train_path = f\"logs/{config_name}/{time_string}/best_train\"\n",
    "best_train_writer = tf.summary.create_file_writer(best_train_path)\n",
    "model_path_best = f\"model/{config_name}/{time_string}/best\"\n",
    "\n",
    "# Hyperparameter\n",
    "iterations = 5000\n",
    "INNER_ITS = 50\n",
    "BATCH_SIZE = 512\n",
    "#reward_function_adapting_agent = lambda d,r: tf.where(d, tf.where(r==0.0,tf.constant(1.0),tf.constant(0.0)), r)\n",
    "epsilon = 1\n",
    "EPSILON_MIN = 0.01\n",
    "EPSILON_DECAY = 0.995\n",
    "POLYAK = 0.9\n",
    "dropout_rate = 0.5, \n",
    "normalisation = True\n",
    "\n",
    "# create buffer\n",
    "best_buffer = Buffer(capacity = 100000,min_size = 100)\n",
    "\n",
    "# create agent\n",
    "env = ConnectFourEnv()\n",
    "env = ConnectFourSelfPLay(ConnectFourEnv)\n",
    "best_agent = DQNAgent(env,best_buffer, batch = BATCH_SIZE, model_path = model_path_best, polyak_update = POLYAK, inner_iterations = INNER_ITS, dropout_rate = dropout_rate, normalisation = normalisation)\n",
    "best_agent.load_models(0)\n",
    "env.set_opponent(best_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad8f2f-9454-4826-ac1a-ff3b8800bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●       ●   ●   ●  \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●       ●   ●   ●  \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   | ● |   |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●       ●   ●   ●  \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   | ○ | ● |   |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●       ●   ●   ●  \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   |   |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ○ |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   | ○ | ● |   |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●       ●   ●   ●  \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ○ |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   | ○ | ● | ○ |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●   ●   ●   ●      \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ○ |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   | ○ | ● | ○ |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●   ●   ●   ●      \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ○ |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   | ○ | ● | ○ |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●   ●   ●   ●   ●      \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   |   |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ○ |   |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   | ○ | ● | ○ |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Player  1\n",
      "  ●   ●       ●   ●   ●   ●  \n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "|   |   |   | ○ |   |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   |   | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   | ● | ● |   |   | ● |\n",
      "+---+---+---+---+---+---+---+\n",
      "| ○ |   | ○ | ● | ○ |   | ○ |\n",
      "+---+---+---+---+---+---+---+\n",
      "  0   1   2   3   4   5   6  \n",
      "\n",
      "Turn Player  0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "player = 0\n",
    "done=False\n",
    "while(True):\n",
    "\n",
    "    print(\"Turn Player \", player)\n",
    "    #print(state)\n",
    "    if not player:\n",
    "        input_action = int(input())\n",
    "    else:  \n",
    "        \n",
    "        state, r, done, info = env.step(input_action)\n",
    "        env.render()\n",
    "    \n",
    "    if(done):\n",
    "        print(\"Player \", player, \" wins\") if r == 1 else print(\"Draw\")\n",
    "        env.render()\n",
    "        #print(state)\n",
    "        break\n",
    "\n",
    "    player = int(not player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9449b4a-b298-4448-83a7-1bc5710fd26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
